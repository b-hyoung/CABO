# 웹 애플리케이션에 적합한 캐싱 전략 선택하기: 사용 사례 기반의 의사결정 과정

웹 애플리케이션을 개발할 때 사용자 경험에 큰 영향을 미치는 요소 중 하나는 '속도'입니다. 특히 외부 API를 통해 데이터를 가져오는 경우, 불필요한 데이터 요청은 느린 로딩 시간과 직접적으로 연결됩니다. 저희는 최근 개발 중인 GitHub 개발자 분석 리포트 서비스 'Cabo'에서 이 문제를 해결하기 위해 어떤 캐싱 전략을 선택했는지, 그 의사결정 과정을 공유하고자 합니다.

## 문제 상황: 반복적인 데이터 요청

'Cabo'는 사용자가 GitHub 사용자 이름을 입력하면 활동 분석, 코드 품질, 협업 스타일 등 다양한 지표를 분석해서 보여주는 서비스입니다. 초기 버전에서는 사용자가 탭을 전환하거나 페이지를 새로고침할 때마다 GitHub API를 통해 데이터를 다시 가져오는 문제가 있었습니다.

-   **탭 전환 문제**: '코드 품질' 탭을 보다가 '협업 스타일' 탭으로 이동하면, 협업 스타일 데이터를 새로 API에 요청합니다. 다시 '코드 품질' 탭으로 돌아오면 이전에 봤던 데이터임에도 불구하고 또다시 API 요청이 발생했습니다.
-   **새로고침 문제**: 페이지를 새로고침하면 이전에 분석했던 모든 데이터가 사라져 처음부터 다시 분석을 시작해야 했습니다.

이는 명백히 비효율적이었고, 사용자에게 나쁜 경험을 제공했습니다. 이 문제를 해결하기 위해 저희는 다양한 캐싱 전략을 검토했습니다.

## 대안 검토: 클라이언트 vs 서버

캐싱 전략은 크게 사용자의 브라우저에 데이터를 저장하는 **클라이언트 측 캐싱**과, 우리 서비스의 백엔드에 데이터를 저장하는 **서버 측 캐싱**으로 나눌 수 있습니다.

### 1. 클라이언트 측 캐싱 (Browser-based)

#### 옵션 A: `localStorage`

-   **장점**: 구현이 매우 간단하고, 한 번 저장된 데이터는 페이지를 새로고침해도 즉시 로드되어 사용자 경험이 빠릅니다.
-   **단점**: 브라우저별로 5~10MB의 저장 공간 제한이 있고, 사용자가 브라우저를 바꾸거나 데이터를 직접 삭제하면 캐시가 사라집니다.

초기에는 "수많은 사용자를 검색할 경우"를 우려하여 저장 공간 제한이 문제가 될 것이라고 생각했습니다.

#### 옵션 B: `IndexedDB`

-   **장점**: `localStorage`보다 훨씬 큰 대용량 데이터(수백 MB 이상)를 저장할 수 있는 브라우저 내장 데이터베이스입니다.
-   **단점**: 기능이 강력한 만큼 `localStorage`에 비해 구현이 훨씬 복잡하여, 간단한 키-값 저장 이상의 기능이 필요 없는 현 상황에서는 과도한 기술(Overkill)이라고 판단했습니다.

### 2. 서버 측 캐싱 (Backend-based)

#### 옵션 C: Redis 등을 이용한 서버 캐시

-   **장점**: 중앙화된 캐시로 모든 사용자가 혜택을 볼 수 있고 (A 사용자가 분석한 결과를 B 사용자도 빠르게 볼 수 있음), 저장 공간의 제약에서 훨씬 자유롭습니다. 대규모 서비스에 가장 적합한 전문가 수준의 해결책입니다.
-   **단점**: Redis와 같은 별도의 캐시 서버를 구축하고 관리해야 하므로 구현 및 유지보수 복잡도가 높고, 추가적인 서버 비용이 발생할 수 있습니다.

## 최종 결정: `localStorage`와 타임스탬프

논의 끝에 저희는 **`localStorage`를 사용하는 것으로 결정**했습니다. 가장 큰 이유는 사용 시나리오를 다시 정의하면서 `localStorage`의 단점이 저희 서비스에 큰 문제가 되지 않는다는 것을 깨달았기 때문입니다.

> "한 사용자가 수백 명의 정보를 한꺼번에 검색할 가능성은 낮고, **평균적으로 100명 내외의 개발자 정보를 저장**하는 것이 대부분일 것이다."

이 가정하에 다시 계산해보니,

-   개발자 1명당 데이터(활동, 품질, 협업) 크기를 약 70KB로 추산
-   100명 분량의 데이터는 **약 7MB**

이는 `localStorage`의 일반적인 용량 제한(5~10MB) 내에 충분히 들어오는 수치였습니다. 따라서 확장성보다는 **구현의 단순성과 즉각적인 사용자 경험 개선**에 집중하기로 했습니다.

### 데이터 신선도 문제 해결

`localStorage`는 데이터가 만료되지 않고 계속 남는다는 단점이 있습니다. 이를 해결하기 위해 **타임스탬프(Timestamp)를 활용한 캐시 무효화 전략**을 추가했습니다.

1.  데이터를 `localStorage`에 저장할 때, 저장하는 시점의 타임스탬프를 함께 기록합니다.
2.  데이터를 불러올 때 타임스탬프를 확인하여, **저장된 지 1주일이 지난 데이터는 오래된 것으로 간주하고 API를 통해 새로 가져옵니다.**
3.  1주일이 지나지 않은 데이터는 `localStorage`에서 바로 불러와 사용자에게 즉시 보여줍니다.

## 추가 개선: 백그라운드 프리페칭(Pre-fetching)을 통한 사용자 경험 최적화

`localStorage` 캐싱을 통해 새로고침 및 반복적인 탭 클릭 문제를 해결했지만, 여전히 개선할 점이 존재했습니다. 바로 **첫 로딩 경험**입니다.

### 발견한 문제

사용자가 처음 리포트 페이지에 진입하면 '활동 분석' 탭의 데이터만 로드됩니다. 이후 사용자가 '코드 품질' 탭을 처음 클릭하면, 그제야 해당 데이터 로딩이 시작되어 로딩 화면을 봐야만 했습니다. 캐시가 없는 첫 방문 시에는 모든 탭을 한 번씩 눌러봐야 모든 데이터가 캐싱되는 구조였습니다.

### 해결 방안: 프리페칭 도입

저희는 이 "기다림"을 최소화하기 위해 **프리페칭(Pre-fetching)** 전략을 도입했습니다.

1.  사용자가 페이지에 처음 진입하면, 가장 먼저 보이는 **'활동 분석' 데이터를 최우선으로 로드**합니다.
2.  '활동 분석' 데이터 로딩이 완료되어 화면에 렌더링되면, **백그라운드에서 '코드 품질'과 '협업 스타일' 탭의 데이터를 미리 가져오기 시작**합니다.

React에서는 `useEffect` 훅을 사용하여 이 로직을 간단하게 구현할 수 있습니다.

```javascript
// 1. 메인 데이터(활동 분석)를 가져옵니다.
useEffect(() => {
  getDeveloperData();
}, [getDeveloperData]);

// 2. 메인 데이터 로딩이 완료되면, 다른 탭 데이터를 미리 가져옵니다.
useEffect(() => {
  if (developer) { // 'developer'는 활동 분석 데이터입니다.
    fetchQualityData();
    fetchCollaborationData();
  }
}, [developer, fetchQualityData, fetchCollaborationData]);
```

### 개선 결과

이 방식을 통해 사용자는 첫 화면(활동 분석)을 빠르게 보면서 다른 작업을 할 수 있고, 그사이에 다른 탭들의 데이터는 백그라운드에서 로드됩니다. 결과적으로 사용자가 '코드 품질'이나 '협업 스타일' 탭을 클릭했을 때는, 이미 데이터가 준비되어 있어 **로딩 시간 없이 즉시 콘텐츠를 볼 수 있게 됩니다.** 이는 전체적인 애플리케이션의 반응성을 크게 향상시켜 훨씬 쾌적한 사용자 경험을 제공합니다.

## 결론

모든 기술 결정에는 트레이드오프가 따릅니다. 저희는 'Cabo' 서비스의 현재 규모와 예상 사용 시나리오를 바탕으로, 서버 캐싱이라는 강력하지만 복잡한 해결책 대신 `localStorage`라는 단순하고 효율적인 해결책을 선택했습니다. 여기에 타임스탬프 기반의 데이터 만료 정책과 백그라운드 프리페칭 전략을 결합함으로써, **적은 노력으로 즉각적인 성능 개선과 뛰어난 사용자 경험이라는 두 마리 토끼**를 잡을 수 있었습니다.

서비스가 성장하여 더 많은 사용자와 데이터를 처리해야 하는 시점이 온다면, 그때 서버 측 캐싱으로 전환하는 것을 다음 단계로 고려할 것입니다. 여러분의 프로젝트 상황에 맞는 최적의 캐싱 전략을 찾는 데 이 글이 도움이 되기를 바랍니다.
